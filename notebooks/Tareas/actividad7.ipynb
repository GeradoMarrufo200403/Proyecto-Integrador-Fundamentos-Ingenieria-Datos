{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d864847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# CONFIGURACIÃ“N\n",
    "# Cambia 'postgres' si tu usuario es diferente\n",
    "# Cambia 'TU_CONTRASEÃ‘A_AQUI' por tu contraseÃ±a real de PostgreSQL\n",
    "USER = \"postgres\"\n",
    "PASSWORD = \"GGmp200403\" \n",
    "HOST = \"localhost\"\n",
    "PORT = \"5432\"\n",
    "DB = \"pronto_lab\"\n",
    "\n",
    "# CREAR CONEXIÃ“N\n",
    "connection_str = f\"postgresql+psycopg2://{USER}:{PASSWORD}@{HOST}:{PORT}/{DB}\"\n",
    "engine = create_engine(connection_str)\n",
    "\n",
    "# PROBAR CONEXIÃ“N\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        print(\"âœ… Â¡Ã‰xito! ConexiÃ³n OK a la base de datos:\", DB)\n",
    "except Exception as e:\n",
    "    print(\"âŒ Error de conexiÃ³n. Revisa tu contraseÃ±a o si creaste la base de datos.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8ca65e",
   "metadata": {},
   "source": [
    "Creacion de tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2361bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# DefiniciÃ³n del esquema y tablas (DDL)\n",
    "ddl_script = \"\"\"\n",
    "CREATE SCHEMA IF NOT EXISTS etl_project;\n",
    "\n",
    "-- 1. Tabla de ESTACIONES (Stations)\n",
    "DROP TABLE IF EXISTS etl_project.stations CASCADE;\n",
    "CREATE TABLE etl_project.stations (\n",
    "    station_id VARCHAR(50) PRIMARY KEY,\n",
    "    name VARCHAR(150),\n",
    "    lat NUMERIC,\n",
    "    long NUMERIC,\n",
    "    install_date DATE,\n",
    "    install_dockcount INT,\n",
    "    modification_date DATE,\n",
    "    current_dockcount INT,\n",
    "    decommission_date DATE\n",
    ");\n",
    "\n",
    "-- 2. Tabla de CLIMA (Weather)\n",
    "DROP TABLE IF EXISTS etl_project.weather CASCADE;\n",
    "CREATE TABLE etl_project.weather (\n",
    "    date DATE PRIMARY KEY,\n",
    "    max_temperature_f INT,\n",
    "    mean_temperature_f INT,\n",
    "    min_temperature_f INT,\n",
    "    max_dew_point_f INT,\n",
    "    mean_dew_point_f INT,\n",
    "    min_dew_point_f INT,\n",
    "    max_humidity INT,\n",
    "    mean_humidity INT,\n",
    "    min_humidity INT,\n",
    "    max_sea_level_pressure_in NUMERIC,\n",
    "    mean_sea_level_pressure_in NUMERIC,\n",
    "    min_sea_level_pressure_in NUMERIC,\n",
    "    max_visibility_miles NUMERIC,\n",
    "    mean_visibility_miles NUMERIC,\n",
    "    min_visibility_miles NUMERIC,\n",
    "    max_wind_speed_mph INT,\n",
    "    mean_wind_speed_mph INT,\n",
    "    max_gust_speed_mph INT,\n",
    "    precipitation_in NUMERIC,\n",
    "    events VARCHAR(100)\n",
    ");\n",
    "\n",
    "-- 3. Tabla de VIAJES (Trips)\n",
    "DROP TABLE IF EXISTS etl_project.trips CASCADE;\n",
    "CREATE TABLE etl_project.trips (\n",
    "    trip_id INT PRIMARY KEY,\n",
    "    starttime TIMESTAMP,\n",
    "    stoptime TIMESTAMP,\n",
    "    bikeid VARCHAR(50),\n",
    "    tripduration NUMERIC,\n",
    "    from_station_id VARCHAR(50),\n",
    "    from_station_name VARCHAR(150),\n",
    "    to_station_id VARCHAR(50),\n",
    "    to_station_name VARCHAR(150),\n",
    "    usertype VARCHAR(50),\n",
    "    gender VARCHAR(20),\n",
    "    birthyear NUMERIC,\n",
    "    -- Llaves forÃ¡neas que conectan viajes con estaciones\n",
    "    FOREIGN KEY (from_station_id) REFERENCES etl_project.stations(station_id),\n",
    "    FOREIGN KEY (to_station_id) REFERENCES etl_project.stations(station_id)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Ejecutar el cÃ³digo SQL\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(ddl_script))\n",
    "    conn.commit()\n",
    "    print(\"âœ… Tablas 'stations', 'weather' y 'trips' creadas exitosamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a532531f",
   "metadata": {},
   "source": [
    "CÃ³digo de Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da5bd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sqlalchemy import text\n",
    "\n",
    "# RUTAS\n",
    "file_stations = 'data/station.csv'\n",
    "file_weather = 'data/weather.csv'\n",
    "file_trips = 'data/trip.csv'\n",
    "\n",
    "# --- 1. CARGAR STATIONS ---\n",
    "def cargar_stations():\n",
    "    print(\"ðŸ“‚ Procesando STATIONS...\")\n",
    "    df = pd.read_csv(file_stations)\n",
    "    cols_fecha = ['install_date', 'modification_date', 'decommission_date']\n",
    "    for col in cols_fecha:\n",
    "        df[col] = pd.to_datetime(df[col], format='mixed', errors='coerce')\n",
    "    df.to_sql('stations', con=engine, schema='etl_project', if_exists='append', index=False)\n",
    "    print(\"âœ… Stations cargada.\")\n",
    "\n",
    "# --- 2. CARGAR WEATHER ---\n",
    "def cargar_weather():\n",
    "    print(\"ðŸ“‚ Procesando WEATHER...\")\n",
    "    df = pd.read_csv(file_weather)\n",
    "    if 'Date' in df.columns:\n",
    "        df = df.rename(columns={'Date': 'date'})\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    mapa_columnas = {\n",
    "        'Max_Temperature_F': 'max_temperature_f',\n",
    "        'Mean_Temperature_F': 'mean_temperature_f',\n",
    "        'Min_TemperatureF': 'min_temperature_f',\n",
    "        'Max_Dew_Point_F': 'max_dew_point_f',\n",
    "        'MeanDew_Point_F': 'mean_dew_point_f',\n",
    "        'Min_Dewpoint_F': 'min_dew_point_f',\n",
    "        'Max_Humidity': 'max_humidity',\n",
    "        'Mean_Humidity': 'mean_humidity',\n",
    "        'Min_Humidity': 'min_humidity',\n",
    "        'Max_Sea_Level_Pressure_In': 'max_sea_level_pressure_in',\n",
    "        'Mean_Sea_Level_Pressure_In': 'mean_sea_level_pressure_in',\n",
    "        'Min_Sea_Level_Pressure_In': 'min_sea_level_pressure_in',\n",
    "        'Max_Visibility_Miles': 'max_visibility_miles',\n",
    "        'Mean_Visibility_Miles': 'mean_visibility_miles',\n",
    "        'Min_Visibility_Miles': 'min_visibility_miles',\n",
    "        'Max_Wind_Speed_MPH': 'max_wind_speed_mph',\n",
    "        'Mean_Wind_Speed_MPH': 'mean_wind_speed_mph',\n",
    "        'Max_Gust_Speed_MPH': 'max_gust_speed_mph',\n",
    "        'Precipitation_In': 'precipitation_in',\n",
    "        'Events': 'events'\n",
    "    }\n",
    "    df = df.rename(columns=mapa_columnas)\n",
    "    columnas_sql = list(mapa_columnas.values()) + ['date']\n",
    "    df_clean = df[df.columns.intersection(columnas_sql)].copy()\n",
    "    \n",
    "    for col in df_clean.columns:\n",
    "        if col != 'date' and col != 'events':\n",
    "            df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "\n",
    "    df_clean.to_sql('weather', con=engine, schema='etl_project', if_exists='append', index=False)\n",
    "    print(\"âœ… Weather cargada.\")\n",
    "\n",
    "# --- 3. CARGAR TRIPS (VersiÃ³n Anti-Duplicados) ---\n",
    "def cargar_trips_final():\n",
    "    print(\"ðŸ“‚ Procesando TRIPS (Validando FKs y Duplicados)...\")\n",
    "    \n",
    "    # a. Leer CSV\n",
    "    df_trips = pd.read_csv(file_trips, on_bad_lines='skip', low_memory=False)\n",
    "    \n",
    "    # b. ELIMINAR DUPLICADOS DE ID (NUEVO)\n",
    "    cant_inicial = len(df_trips)\n",
    "    df_trips = df_trips.drop_duplicates(subset=['trip_id'], keep='first')\n",
    "    cant_duplicados = cant_inicial - len(df_trips)\n",
    "    if cant_duplicados > 0:\n",
    "        print(f\"   âš ï¸ Se eliminaron {cant_duplicados} registros con trip_id duplicado.\")\n",
    "    \n",
    "    # c. Filtrar por Estaciones VÃ¡lidas (FK)\n",
    "    with engine.connect() as conn:\n",
    "        valid_ids = pd.read_sql(\"SELECT station_id FROM etl_project.stations\", conn)['station_id'].tolist()\n",
    "    \n",
    "    df_clean = df_trips[\n",
    "        df_trips['from_station_id'].isin(valid_ids) & \n",
    "        df_trips['to_station_id'].isin(valid_ids)\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"   âš ï¸ Se eliminaron {len(df_trips) - len(df_clean)} viajes con estaciones desconocidas.\")\n",
    "\n",
    "    # d. Fechas y Carga\n",
    "    df_clean['starttime'] = pd.to_datetime(df_clean['starttime'], format='mixed')\n",
    "    df_clean['stoptime'] = pd.to_datetime(df_clean['stoptime'], format='mixed')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    df_clean.to_sql('trips', con=engine, schema='etl_project', if_exists='append', index=False)\n",
    "    end_time = time.time()\n",
    "    print(f\"âœ… Trips cargada exitosamente en {end_time - start_time:.2f} s.\")\n",
    "\n",
    "# --- EJECUCIÃ“N ---\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        print(\"ðŸ§¹ Limpiando tablas para reintentar...\")\n",
    "        conn.execute(text(\"TRUNCATE TABLE etl_project.trips, etl_project.weather, etl_project.stations CASCADE;\"))\n",
    "        conn.commit()\n",
    "\n",
    "    cargar_stations()\n",
    "    cargar_weather()\n",
    "    cargar_trips_final()\n",
    "    \n",
    "    print(\"\\nðŸš€ Â¡TODO CARGADO CORRECTAMENTE!\")\n",
    "    \n",
    "    # VerificaciÃ³n final\n",
    "    with engine.connect() as conn:\n",
    "        print(\"Stations:\", conn.execute(text(\"SELECT COUNT(*) FROM etl_project.stations\")).scalar())\n",
    "        print(\"Weather:\", conn.execute(text(\"SELECT COUNT(*) FROM etl_project.weather\")).scalar())\n",
    "        print(\"Trips:\", conn.execute(text(\"SELECT COUNT(*) FROM etl_project.trips\")).scalar())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd40e44",
   "metadata": {},
   "source": [
    "ActualizaciÃ³n de datos Upsert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124661af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# 1. Definimos la sentencia UPSERT\n",
    "# FÃ­jate en la parte \"ON CONFLICT (date) DO UPDATE...\"\n",
    "sql_upsert = text(\"\"\"\n",
    "INSERT INTO etl_project.weather (date, max_temperature_f, mean_temperature_f, events)\n",
    "VALUES (:date, :max_temp, :mean_temp, :events)\n",
    "ON CONFLICT (date) \n",
    "DO UPDATE SET \n",
    "    max_temperature_f = EXCLUDED.max_temperature_f,\n",
    "    mean_temperature_f = EXCLUDED.mean_temperature_f,\n",
    "    events = EXCLUDED.events;\n",
    "\"\"\")\n",
    "\n",
    "# 2. Datos de prueba (Usaremos una fecha futura para no afectar datos reales)\n",
    "fecha_demo = '2030-01-01'\n",
    "\n",
    "# CASO A: Insertar por primera vez (Temperatura 85Â°F, Soleado)\n",
    "dato_1 = {'date': fecha_demo, 'max_temp': 85, 'mean_temp': 80, 'events': 'Sunny'}\n",
    "\n",
    "# CASO B: El clima cambiÃ³, corregimos el dato (Temperatura 30Â°F, Nieve)\n",
    "dato_2 = {'date': fecha_demo, 'max_temp': 30, 'mean_temp': 25, 'events': 'Snow'}\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    # --- EjecuciÃ³n 1 ---\n",
    "    conn.execute(sql_upsert, dato_1)\n",
    "    conn.commit()\n",
    "    print(\"1ï¸âƒ£ Primera ejecuciÃ³n: Se insertÃ³ el registro del 2030 (Soleado).\")\n",
    "    \n",
    "    # Verificamos\n",
    "    res1 = conn.execute(text(f\"SELECT * FROM etl_project.weather WHERE date = '{fecha_demo}'\")).fetchone()\n",
    "    print(f\"   Resultado DB: {res1.max_temperature_f}Â°F - {res1.events}\")\n",
    "\n",
    "    # --- EjecuciÃ³n 2 (Upsert) ---\n",
    "    print(\"\\nðŸ”„ Ejecutando de nuevo con datos cambiados (Nieve)...\")\n",
    "    conn.execute(sql_upsert, dato_2)\n",
    "    conn.commit()\n",
    "    print(\"2ï¸âƒ£ Segunda ejecuciÃ³n: Se actualizÃ³ el registro existente (sin error de duplicado).\")\n",
    "    \n",
    "    # Verificamos cambio\n",
    "    res2 = conn.execute(text(f\"SELECT * FROM etl_project.weather WHERE date = '{fecha_demo}'\")).fetchone()\n",
    "    print(f\"   Resultado DB: {res2.max_temperature_f}Â°F - {res2.events}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6610a402",
   "metadata": {},
   "source": [
    "CÃ³digo de Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9201032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# 1. La consulta \"pesada\"\n",
    "# Busca viajes de un mes especÃ­fico y cuenta cuÃ¡ntos salieron de cada estaciÃ³n\n",
    "query_pesada = \"\"\"\n",
    "SELECT from_station_id, COUNT(*) as total_viajes\n",
    "FROM etl_project.trips\n",
    "WHERE starttime >= '2015-01-01' AND starttime < '2015-02-01'\n",
    "GROUP BY from_station_id\n",
    "ORDER BY total_viajes DESC;\n",
    "\"\"\"\n",
    "\n",
    "def medir_tiempo(mensaje):\n",
    "    start = time.time()\n",
    "    # Ejecutamos la consulta\n",
    "    pd.read_sql(query_pesada, engine)\n",
    "    end = time.time()\n",
    "    duracion = end - start\n",
    "    print(f\"{mensaje}: {duracion:.5f} segundos\")\n",
    "    return duracion\n",
    "\n",
    "print(\"--- ðŸ INICIANDO PRUEBA DE VELOCIDAD ðŸ ---\")\n",
    "\n",
    "# A. Medir SIN Ã­ndices\n",
    "# (Para estar seguros, borramos Ã­ndices si existÃ­an de pruebas anteriores)\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"DROP INDEX IF EXISTS etl_project.idx_starttime;\"))\n",
    "    conn.execute(text(\"DROP INDEX IF EXISTS etl_project.idx_station_id;\"))\n",
    "    conn.commit()\n",
    "\n",
    "tiempo_sin = medir_tiempo(\"ðŸ¢ Tiempo SIN Ã­ndices\")\n",
    "\n",
    "# B. Crear los Ã­ndices\n",
    "print(\"\\nðŸ› ï¸ Creando Ã­ndices (optimizando)...\")\n",
    "with engine.connect() as conn:\n",
    "    start_idx = time.time()\n",
    "    conn.execute(text(\"CREATE INDEX idx_starttime ON etl_project.trips(starttime);\"))\n",
    "    conn.execute(text(\"CREATE INDEX idx_station_id ON etl_project.trips(from_station_id);\"))\n",
    "    conn.commit()\n",
    "    print(f\"   Ãndices creados en {time.time() - start_idx:.2f} s.\")\n",
    "\n",
    "# C. Medir CON Ã­ndices\n",
    "tiempo_con = medir_tiempo(\"âš¡ Tiempo CON Ã­ndices\")\n",
    "\n",
    "# D. ConclusiÃ³n\n",
    "mejora = tiempo_sin - tiempo_con\n",
    "porcentaje = (mejora / tiempo_sin) * 100\n",
    "print(f\"\\nðŸ“Š CONCLUSIÃ“N: La consulta fue {porcentaje:.1f}% mÃ¡s rÃ¡pida.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
